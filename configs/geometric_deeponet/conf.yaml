callbacks:
  checkpoint:
    dirpath: ${CHKPT_DIR}
    filename: ${CHKPT_NAME}
    mode: min                
    monitor: val_loss        
    save_top_k: 1            
  early_stopping:
    monitor: val_loss        
    patience: 1000           
    mode: min                

data:
  batch_size: 32
  file_path_test_x: ${DATA_DIR}/fpo_test_x.npy
  file_path_test_y: ${DATA_DIR}/fpo_test_y.npy
  file_path_train_x: ${DATA_DIR}/fpo_train_x.npy
  file_path_train_y: ${DATA_DIR}/fpo_train_y.npy
  shuffle: true              
  type: collocation          
  every_nth_timestep: 8      # Use starting timesteps 0, n, 2n, ... for generating training/eval samples. 1 means use all possible.

model:
  includePressure: false
  height: 256              
  width: 1024              
  domain_length_x: 16.0    
  domain_length_y: 4.0     
  num_input_timesteps: 16  # Nb: Length of the input sequence (using ground truth)
  final_timestep: 60       
  # --- Network Architecture ---
  input_channels_loc: 2    # Base location channels (x, y) - SDF is added internally
  output_channels: 3       # Number of output fields (e.g., u, v, p)
  modes: 256               # Dimension of the latent space in DeepONet stages
  # CNN Encoder Params
  cnn_c1: 64
  cnn_c2: 32
  cnn_c3: 16
  cnn_fc1: 32
  cnn_fc2: 16
  # DeepONet MLP Layers (Hidden dims)
  branch_stage1_layers: [256, 128] # CNN -> modes (ReLU)
  trunk_stage1_layers: [128, 128]  # (x,y,sdf) -> modes (ReLU)
  branch_stage2_layers: [128, 128] # modes_avg -> modes*C_out (ReLU)
  trunk_stage2_layers: [128, 128]  # modes_pointwise -> modes*C_out (Sine)
  lr: 0.0001               
  plot_path: ${PLOT_DIR} 

wandb:
  project: "TD-geodeponet"
  name:   "16in_stride8"
    
sweep_parameters:
  parameters:
    trainer.seed:
      values: [0]

trainer:
  accelerator: gpu        
  devices: 1              
  log_every_n_steps: 10   
  max_epochs: 1000
  seed: 0
  precision: 16-mixed      # Options: "16-mixed", "bf16-mixed", "32-true", "64-true"
